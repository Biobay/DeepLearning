LINK DATASET 
https://github.com/cristobalmitchell/pokedex/

. Specifiche e traccia ufficiale del progetto
Testo ufficiale e dettagli delle richieste
Deep_Learning_2025_VI.pdf (Traccia - Politecnico di Bari)
Qui trovi tutte le condizioni, architettura richiesta, deliverables, consigli e vincoli.

2. Dataset Pokémon
Dataset completo (sprite + descrizioni + metadata)
https://github.com/cristobalmitchell/pokedex/
Da qui scarichi immagini, descrizioni e tutte le informazioni necessarie per il preprocessing e il training.

3. BERT e Transformer per l’encoder testuale
BERT-mini (embedding pre-addestrati, documentazione, paper)
https://github.com/google-research/bert
Qui trovi sia il codice che i modelli pre-addestrati e la spiegazione del funzionamento di BERT.

4. Modelli e paper di riferimento per Text-to-Image con Attention
AttnGAN (paper originale su arXiv)
https://arxiv.org/abs/1711.10485
È il paper di riferimento per text-to-image con attenzione tra testo e immagine, molto simile a quanto richiesto dal progetto.

5. Esempi di fine-tuning su dataset Pokémon (Stable Diffusion, ControlNet)
Fine-tuning Stable Diffusion su Pokémon (esempio open source)
https://github.com/caetas/FineTune_SD
Progetto che mostra come adattare un generatore di immagini a descrizioni Pokémon, utile per pipeline, preprocessing e demo.

6. Documentazione PyTorch (implementazione, training, moduli custom)
Documentazione ufficiale PyTorch
https://docs.pytorch.org/tutorials/beginner/pytorch_with_examples.html
Tutorial pratici per costruire modelli custom, dataset, training loop, moduli nn.Module, DataLoader, ecc..

Consiglio pratico
Parti sempre dalla traccia ufficiale , poi scarica e analizza il dataset . Per l’encoder studia BERT , per il decoder e l’attenzione guarda AttnGAN  e gli esempi di fine-tuning . Per tutta la parte di implementazione, training e debug, la documentazione PyTorch  è la tua guida di riferimento.

Se vuoi approfondire, puoi anche consultare direttamente i paper citati nelle sezioni “Related Work” di AttnGAN e nella documentazione BERT.